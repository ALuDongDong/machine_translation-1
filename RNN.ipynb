{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EncoderDecoder\n",
    "----\n",
    "- 1 如果我们现在要做个中英文翻译,比如我是中国人翻译成 ‘i am Chinese’.这时候我们会发现输入有 5个中文字,而输出只有三个英文单词. 也就是输入长度并不等于输出长度.这时候我们会引入一种 编码器-解码器的模型也就是 (Encoder-Decoder).首先我们通过编码器 对输入 ‘我是中国人’ 进行信息编码, 之后将生成的编码数据输入 decoder 进行解码.一般编码器和解码器 都会使用循环神经网络.\n",
    "- 2 当然为了使机器知道句子的结束我们会在每个句子后面增加 一个$<eos>$表示句子的结束.使得电脑可以进行识别.在训练的时候 我们也一般会在解码器的第一个输入阶段加上$<bos>$表示预测的开始.\n",
    "    \n",
    "- 3 同时为了使每个句子保持相同长度,我们 会人为预先规定句子长度,若句子没有达到长度,那么我们会对句子进行填充,使得其长度达到规定长度.\n",
    "- 4 作为编码器的输入 我们一般使用 C = q(h1, h2…ht)作为第一个隐藏层输入，一般的我们也可以直接使用c = ht，不用包含之前所有的隐藏层信息。\n",
    "- 5 在训练的时候我们一般会使用强制教学，也就是 不把y_hat1的预测数据当做编码器的第二个输入， 而是直接用标签数据的y1当做输入。\n",
    "- 6 当我们使用贪心算法再对y进行softmax的时候，我们对每个输出的y进行当前最优的选择。可能会达到全局最优的情况\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "import io\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchtext.vocab as Vocab\n",
    "import torch.utils.data as Data\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = \"./data\"\n",
    "TRIAN_DIR = os.path.join(DATA_ROOT, \"train\")\n",
    "if not os.path.exists(TRIAN_DIR):\n",
    "    os.makedirs(TRIAN_DIR)\n",
    "    \n",
    "PAD, UNK, BOS, EOS  = \"<pad>\", \"<unk>\", \"<bos>\", \"<eos>\"\n",
    "N_PAD, N_UNK, N_BOS, N_EOS = 0, 1, 2, 3\n",
    "\n",
    "ZH_VOCAB_SIZE = 4000\n",
    "ZH_VOCAB_OUTPUT = os.path.join(TRIAN_DIR, \"zh.vocab\")\n",
    "ZH_DEV = os.path.join(TRIAN_DIR, \"zh.dev\")\n",
    "ZH_TRAIN = os.path.join(TRIAN_DIR, \"zh.train\")\n",
    "\n",
    "EN_VOCAB_SIZE = 10000\n",
    "EN_VOCAB_OUTPUT = os.path.join(TRIAN_DIR, \"en.vocab\")\n",
    "EN_DEV = os.path.join(TRIAN_DIR, \"en.dev\")   # 这个暂时没用？\n",
    "EN_TRAIN = os.path.join(TRIAN_DIR, \"en.train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    data = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            sent = line.strip()\n",
    "            if sent:\n",
    "                seq = [int(i) for i in sent.split()]\n",
    "                data.append(seq)\n",
    "    return data\n",
    "\n",
    "class Tokenizer(object):\n",
    "    \"\"\"解析器\"\"\"\n",
    "    def __init__(self, vocab_file):\n",
    "        self.vocab_file = vocab_file\n",
    "        self.vocab_list = self.load_vocab()\n",
    "        self.word2idx = self.build_word2idx()\n",
    "        self.idx2word = self.bulid_idx2word()\n",
    "        \n",
    "    def load_vocab(self):\n",
    "        vocab = []\n",
    "        with open(self.vocab_file, \"r\") as f:\n",
    "            for word in f:\n",
    "                vocab.append(word.strip())\n",
    "        return vocab\n",
    "    \n",
    "    def build_word2idx(self):\n",
    "        word2idx = {w:i for i, w in enumerate(self.vocab_list)}\n",
    "        return word2idx\n",
    "    \n",
    "    def bulid_idx2word(self):\n",
    "        idx2word = {i:w for i, w in enumerate(self.vocab_list)}\n",
    "        return idx2word\n",
    "    \n",
    "    def wtoi(self, word_list):\n",
    "        idx_list = []\n",
    "        for word in word_list:\n",
    "            if word not in self.word2idx:\n",
    "                idx = self.word2idx.get(UNK)\n",
    "            else:\n",
    "                idx = self.word2idx.get(word)\n",
    "            idx_list.append(idx)\n",
    "        return idx_list\n",
    "        \n",
    "    def itow(self, idx_list):\n",
    "        word_list = []\n",
    "        for idx in idx_list:\n",
    "            word = self.idx2word.get(idx)\n",
    "            word_list.append(word)\n",
    "        return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 drop_prob=0, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size, num_hiddens, num_layers, dropout=drop_prob)\n",
    "\n",
    "    def forward(self, inputs, state):\n",
    "        # 输入形状是(批量大小, 时间步数)。将输出互换样本维和时间步维\n",
    "        embedding = self.embedding(inputs.long()).permute(1, 0, 2) # (seq_len, batch, input_size)\n",
    "        return self.rnn(embedding, state)\n",
    "\n",
    "    def begin_state(self):\n",
    "        return None # 隐藏态初始化为None时PyTorch会自动初始化为0\n",
    "\n",
    "    \n",
    "def attention_model(input_size, attention_size):\n",
    "    model = nn.Sequential(nn.Linear(input_size, \n",
    "                                    attention_size, bias=False),\n",
    "                          nn.Tanh(),\n",
    "                          nn.Linear(attention_size, 1, bias=False))\n",
    "    return model\n",
    "\n",
    "\n",
    "def attention_forward(model, enc_states, dec_state):\n",
    "    \"\"\"\n",
    "    enc_states: (时间步数, 批量大小, 隐藏单元个数)\n",
    "    dec_state: (批量大小, 隐藏单元个数)\n",
    "    \"\"\"\n",
    "    # 将解码器隐藏状态广播到和编码器隐藏状态形状相同后进行连结\n",
    "    dec_states = dec_state.unsqueeze(dim=0).expand_as(enc_states)\n",
    "    enc_and_dec_states = torch.cat((enc_states, dec_states), dim=2)\n",
    "    e = model(enc_and_dec_states)  # 形状为(时间步数, 批量大小, 1)\n",
    "    alpha = F.softmax(e, dim=0)  # 在时间步维度做softmax运算\n",
    "    return (alpha * enc_states).sum(dim=0)  # 返回背景变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 attention_size, drop_prob=0):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.attention = attention_model(2*num_hiddens, attention_size)\n",
    "        # GRU的输入包含attention输出的c和实际输入, 所以尺寸是 num_hiddens+embed_size\n",
    "        self.rnn = nn.GRU(num_hiddens + embed_size, num_hiddens, \n",
    "                          num_layers, dropout=drop_prob)\n",
    "        self.out = nn.Linear(num_hiddens, vocab_size)\n",
    "\n",
    "    def forward(self, cur_input, state, enc_states):\n",
    "        \"\"\"\n",
    "        cur_input shape: (batch, )\n",
    "        state shape: (num_layers, batch, num_hiddens)\n",
    "        \"\"\"\n",
    "        # 使用注意力机制计算背景向量\n",
    "        c = attention_forward(self.attention, enc_states, state[-1])\n",
    "        # 将嵌入后的输入和背景向量在特征维连结, (批量大小, num_hiddens+embed_size)\n",
    "        input_and_c = torch.cat((self.embedding(cur_input), c), dim=1)\n",
    "        # 为输入和背景向量的连结增加时间步维，时间步个数为1\n",
    "        output, state = self.rnn(input_and_c.unsqueeze(0), state)\n",
    "        # 移除时间步维，输出形状为(批量大小, 输出词典大小)\n",
    "        output = self.out(output).squeeze(dim=0)\n",
    "        return output, state\n",
    "\n",
    "    def begin_state(self, enc_state):\n",
    "        # 直接将编码器最终时间步的隐藏状态作为解码器的初始隐藏状态\n",
    "        return enc_state\n",
    "    \n",
    "    \n",
    "def batch_loss(encoder, decoder, X, Y, loss):\n",
    "    batch_size = X.shape[0]\n",
    "    enc_state = encoder.begin_state()\n",
    "    enc_outputs, enc_state = encoder(X, enc_state)\n",
    "    # 初始化解码器的隐藏状态\n",
    "    dec_state = decoder.begin_state(enc_state)\n",
    "    \n",
    "    # 解码器在最初时间步的输入是BOS [out_vocab.stoi[BOS]]\n",
    "    dec_input = torch.tensor([N_BOS] * batch_size).to(device)\n",
    "    # 我们将使用掩码变量mask来忽略掉标签为填充项PAD的损失\n",
    "    mask, num_not_pad_tokens = torch.ones(batch_size,).to(device), 0\n",
    "    \n",
    "    l = torch.tensor([0.0]).to(device)\n",
    "    \n",
    "    out_vocab_eos = torch.tensor([N_BOS]).to(device)\n",
    "    for y in Y.permute(1,0): # Y shape: (batch, seq_len)\n",
    "        dec_output, dec_state = decoder(dec_input, dec_state, enc_outputs)\n",
    "#         print(\"dec_output:\", dec_output, dec_output.size())\n",
    "#         print(\"dec_state:\", dec_state, dec_state.size())\n",
    "#         print(\"y\", y)\n",
    "#         print(\"CrossEntropyLoss:\", loss(dec_output, y))\n",
    "#         print(\"mask\", mask)\n",
    "#         print(\"-\"*30)\n",
    "        l = l + (mask * loss(dec_output, y)).sum()\n",
    "        dec_input = y  # 使用强制教学\n",
    "        num_not_pad_tokens += mask.sum().item()\n",
    "        # EOS后面全是PAD. 下面一行保证一旦遇到EOS接下来的循环中mask就一直是0 out_vocab.stoi[EOS]\n",
    "        \n",
    "        mask = mask * (y != out_vocab_eos).float()\n",
    "    return l / num_not_pad_tokens\n",
    "\n",
    "\n",
    "def train(encoder, decoder, dataset, lr, batch_size, num_epochs):\n",
    "    enc_optimizer = torch.optim.Adam(encoder.parameters(), lr=lr)\n",
    "    dec_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "\n",
    "    loss = nn.CrossEntropyLoss(reduction='none').to(device)\n",
    "    data_iter = Data.DataLoader(dataset, batch_size, shuffle=True)\n",
    "    for epoch in range(num_epochs):\n",
    "        l_sum = 0.0\n",
    "        start = time.time()\n",
    "        n = 0\n",
    "        for X, Y in data_iter:\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            enc_optimizer.zero_grad()\n",
    "            dec_optimizer.zero_grad()\n",
    "            l = batch_loss(encoder, decoder, X, Y, loss)\n",
    "#             print(l)\n",
    "            l.backward()\n",
    "            enc_optimizer.step()\n",
    "            dec_optimizer.step()\n",
    "            l_sum += l.item()\n",
    "            n += 1\n",
    "            if n % 2000 == 0:\n",
    "                print(\"iter -- {}\".format(n))\n",
    "#             break\n",
    "#         if (epoch + 1) % 10 == 0:\n",
    "        end = time.time()\n",
    "    \n",
    "        print(\"epoch %d, loss %.3f, time: %.2f\" % (epoch + 1, l_sum / len(data_iter), end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_data = load_data(EN_TRAIN)\n",
    "zh_data = load_data(ZH_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_len(data):\n",
    "    return max([len(s) for s in data])\n",
    "\n",
    "def min_len(data):\n",
    "    return min([len(s) for s in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[644, 883]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[max_len(en_data), max_len(zh_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[min_len(en_data), min_len(zh_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_one_seq(src_tokens, trg_tokens, max_seq_len):\n",
    "    all_tokens = []\n",
    "    for src, trg in zip(src_tokens, trg_tokens):\n",
    "        src_len = len(src)\n",
    "        trg_len = len(trg)\n",
    "        if src_len > (max_seq_len-1) or trg_len > (max_seq_len-1):\n",
    "            continue\n",
    "        else:\n",
    "            src_tokens = src + [N_EOS] + [N_PAD] * (max_seq_len - src_len - 1)\n",
    "            trg_tokens = trg + [N_EOS] + [N_PAD] * (max_seq_len - trg_len - 1)\n",
    "        all_tokens.append((src_tokens, trg_tokens))\n",
    "    return all_tokens\n",
    "\n",
    "def build_dataset(all_data):\n",
    "    in_data = []\n",
    "    out_data = []\n",
    "    for seq_tuple in all_data:\n",
    "        x, y = seq_tuple\n",
    "        in_data.append(x)\n",
    "        out_data.append(y)\n",
    "    in_data = torch.tensor(in_data)\n",
    "    out_data = torch.tensor(out_data)\n",
    "    return Data.TensorDataset(in_data, out_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 256])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len, batch_size, num_hiddens = 128, 64, 256\n",
    "model = attention_model(2*num_hiddens, seq_len) \n",
    "enc_states = torch.zeros((seq_len, batch_size, num_hiddens))\n",
    "dec_state = torch.zeros((batch_size, num_hiddens))\n",
    "attention_forward(model, enc_states, dec_state).shape # torch.Size([16, 256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = process_one_seq(en_data, zh_data, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178738"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_dataset(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_tokenizer = Tokenizer(EN_VOCAB_OUTPUT)\n",
    "out_tokenizer = Tokenizer(ZH_VOCAB_OUTPUT)\n",
    "in_vocab_len = len(in_tokenizer.word2idx)\n",
    "out_vocab_len = len(out_tokenizer.word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/modules/rnn.py:54: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "embed_size, num_hiddens, num_layers = 256, 256, 1\n",
    "attention_size, drop_prob, lr, batch_size, num_epochs = seq_len, 0.5, 0.01, 2, 50\n",
    "encoder = Encoder(in_vocab_len, embed_size, num_hiddens, num_layers,\n",
    "                  drop_prob)\n",
    "encoder = encoder.to(device)\n",
    "decoder = Decoder(out_vocab_len, embed_size, num_hiddens, num_layers,\n",
    "                  attention_size, drop_prob)\n",
    "decoder = decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter -- 2000\n",
      "iter -- 4000\n",
      "iter -- 6000\n",
      "iter -- 8000\n",
      "iter -- 10000\n",
      "iter -- 12000\n",
      "iter -- 14000\n",
      "iter -- 16000\n",
      "iter -- 18000\n",
      "iter -- 20000\n",
      "iter -- 22000\n",
      "iter -- 24000\n",
      "iter -- 26000\n",
      "iter -- 28000\n",
      "iter -- 30000\n",
      "iter -- 32000\n",
      "iter -- 34000\n",
      "iter -- 36000\n",
      "iter -- 38000\n",
      "iter -- 40000\n",
      "iter -- 42000\n",
      "iter -- 44000\n",
      "iter -- 46000\n",
      "iter -- 48000\n",
      "iter -- 50000\n",
      "iter -- 52000\n",
      "iter -- 54000\n",
      "iter -- 56000\n",
      "iter -- 58000\n",
      "iter -- 60000\n",
      "iter -- 62000\n",
      "iter -- 64000\n",
      "iter -- 66000\n",
      "iter -- 68000\n",
      "iter -- 70000\n",
      "iter -- 72000\n",
      "iter -- 74000\n",
      "iter -- 76000\n",
      "iter -- 78000\n",
      "iter -- 80000\n",
      "iter -- 82000\n",
      "iter -- 84000\n",
      "iter -- 86000\n",
      "iter -- 88000\n",
      "epoch 1, loss nan, time: 12111.99\n",
      "iter -- 2000\n",
      "iter -- 4000\n",
      "iter -- 6000\n",
      "iter -- 8000\n",
      "iter -- 10000\n",
      "iter -- 12000\n",
      "iter -- 14000\n",
      "iter -- 16000\n",
      "iter -- 18000\n",
      "iter -- 20000\n",
      "iter -- 22000\n",
      "iter -- 24000\n",
      "iter -- 26000\n",
      "iter -- 28000\n",
      "iter -- 30000\n",
      "iter -- 32000\n",
      "iter -- 34000\n",
      "iter -- 36000\n",
      "iter -- 38000\n",
      "iter -- 40000\n",
      "iter -- 42000\n",
      "iter -- 44000\n",
      "iter -- 46000\n",
      "iter -- 48000\n",
      "iter -- 50000\n",
      "iter -- 52000\n",
      "iter -- 54000\n",
      "iter -- 56000\n",
      "iter -- 58000\n",
      "iter -- 60000\n",
      "iter -- 62000\n"
     ]
    }
   ],
   "source": [
    "train(encoder, decoder, dataset, lr, batch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
